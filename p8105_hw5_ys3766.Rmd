---
title: "p8105_hw5_ys3766"
author: "Yifan Shi"
date: "2024-11-15"
output: github_document
---
```{r set up, include=FALSE}
library(tidyverse)
library(ggplot2)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Problem 1
```{r}
bday_sim = function(n){

bdays = sample(1:365, size = n, replace = TRUE)

duplicate = length(unique(bdays)) < n

return(duplicate)
}

bday_sim(10)

sim_res = 
  expand_grid(
    n = 2:50,
    iter = 1:10000
  ) %>% 
  mutate(res = map_lgl(n, bday_sim)) %>% 
  group_by(n) %>% 
  summarize(prob = mean(res)) 


sim_res %>% 
  ggplot(aes(x = n, y = prob))+
  geom_point()+
  geom_line()+
   ggtitle("Probability of Shared Birthdays by Group Size") +
  xlab("Group Size") +
  ylab("Probability of Shared Birthdays")
```

The plot shows the probability of at least two people in a group sharing a birthday, with group size ranging from 2 to 50. The probability increased with the size of the group. The probability exceeds 50% in group with 23 or more people, and reached ~97% in a group of 50 people. 

## Problem 2
```{r}
simulate_t_tests <- function(mu, n = 30, sigma = 5, n_sim = 5000) {
  t_results <- replicate(n_sim, {
    data <- rnorm(n, mean = mu, sd = sigma)
    test_result <- t.test(data, mu = 0) %>%
                   broom::tidy() %>%
                   as_tibble()
    c(mu_hat = test_result %>% pull(estimate), 
      p_value = test_result %>% pull(p.value))
  })
  tibble(mu = mu, 
         mu_hat = t_results[1, ], 
         p_value = t_results[2, ])
}

mu_values <- 0:6
simulation_results <- map_df(mu_values, ~simulate_t_tests(.x, n = 30, sigma = 5, n_sim = 5000))

```

```{r}
results_summary <- simulation_results %>%
  mutate(rejected = p_value < 0.05) %>%
  group_by(mu) %>%
  summarise(
    power = mean(rejected),
    avg_mu_hat = mean(mu_hat),
    avg_mu_hat_rejected = mean(mu_hat[rejected]),
    .groups = 'drop' 
  )
```


```{r}
results_summary %>% 
  ggplot(
  aes(x = mu, y = power)) +
  geom_point() +
  geom_line() +
  labs(title = "Power of the Test as a Function of True Mean (mu)",
       x = "true value of mu", y = "Power")

```

```{r}
results_summary %>%  
  ggplot(aes(x = mu)) +
  geom_point(aes(y = avg_mu_hat, color = "All Samples")) +
  geom_line(aes(y = avg_mu_hat, color = "All Samples"), linetype = "dashed") +
  geom_point(aes(y = avg_mu_hat_rejected, color = "Null Reject")) +
  geom_line(aes(y = avg_mu_hat_rejected, color = "Null Reject")) +
  labs(title = "Average Estimates of Mu",
       x = "True Mean (mu)", 
       y = "Average Estimate of Mu"
       )
```

The sample average of μ across tests where the null is rejected is typically higher than the true μ, which is especially noticeable at lower true μ values and tends to converge as μ increases.

When the null hypothesis is rejected, it is often because the sample mean is sufficiently extreme compared to the hypothesized mean. In cases where μ is closer to 0, but the null is rejected, it typically means that the sample mean was unusually high (or low), leading to an overestimate of μ. As μ increases, the likelihood of rejecting the null hypothesis because of random variation rather than the actual effect (i.e., the true μ) decreases, making the estimate more accurate.


## Problem 3
```{r}
homicide_df = read_csv(file = "data/homicide-data.csv", 
                       na = c("Unknown", "NA", "")) %>% 
  mutate(
    reported_date = as.Date(as.character(reported_date), 
                            format = "%y%m%d"))
```

```{r}
summary(homicide_df)
```


The homicide dataset comprises `r nrow(homicide_df)` homicide cases from various U.S. cities, spanning from `r min(homicide_df %>% pull(reported_date), na.rm = TRUE)` to `r max(homicide_df %>% pull(reported_date), na.rm = TRUE)`. Key variables include **victim details** (name, race, age, sex), **city** and **state** of the incident, **geographical coordinates**, and **case disposition status**. Notably, there is a significant amount of missing data, particularly for `reported_date` (`r sum(is.na(homicide_df %>% pull(reported_date)))` entries missing) and `victim_age` (`r sum(is.na(homicide_df %>% pull(victim_age)))` entries missing). The disposition statuses categorize whether cases remain open or are closed without arrest.


```{r}
homicide_summary <- homicide_df %>%
  mutate(city_state = paste(city, state, sep = ", ")) %>%
  group_by(city_state) %>%
  summarise(
    total_homicides = n(),
    unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest"), na.rm = TRUE),
    .groups = 'drop'
  ) %>% 
  filter(city_state!="Tulsa, AL")

knitr::kable(homicide_summary)
```


```{r}
baltimore_result <- homicide_summary %>%
  filter(city_state == "Baltimore, MD") %>%
  summarise(prop_test_result = list(prop.test(unsolved_homicides, total_homicides))) %>%
  mutate(tidy_result = map(prop_test_result, broom::tidy)) %>%
  unnest(tidy_result) %>% 
  select(estimate,conf.low, conf.high)
  

knitr::kable(baltimore_result, 
             col.names = c("Estimate", "Lower CI", "Upper CI"),
             caption = "Proportion of Unsolved Homicides in Baltimore, MD")

```


```{r}
unsolved_prop <-  function(unsolved, total){
  prop_test_result <- prop.test(unsolved, total)
  broom::tidy(prop_test_result) %>% 
    select(estimate, conf.low, conf.high)
}

homicide_test <- homicide_summary %>% 
  mutate(
    prop_results = purrr::map2(unsolved_homicides, total_homicides, ~unsolved_prop(.x, .y))
  ) %>%
  unnest(prop_results)

knitr::kable(homicide_test)
```

```{r}
ggplot(homicide_test, aes(x = reorder(city_state, -estimate), y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  labs(
    title = "Proportion of Unsolved Homicides by City",
    x = "City, State",
    y = "Proportion of Unsolved Homicides"
  ) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))  
```

